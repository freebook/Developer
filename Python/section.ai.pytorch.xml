<?xml version="1.0" encoding="UTF-8"?>
<chapter id="index"><?dbhtml dir="pytorch" ?>
	<title>PyTorch</title>
	<section>
		<title>安装 torch</title>
		<programlisting>
			<![CDATA[
pip install --upgrade pip
pip install torch torchvision numpy
			]]>
		</programlisting>
		<section id="torchinfo">
			<title>torchinfo</title>
			<screen>
			<![CDATA[
pip install torchinfo
			]]>
			</screen>
			<programlisting>
			<![CDATA[
    from torchinfo import summary

    summary(mymodel)						
			]]>
			</programlisting>
			<screen>
			<![CDATA[
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
mymodel                                  --
├─Sequential: 1-1                        --
│    └─Conv2d: 2-1                       640
│    └─ReLU: 2-2                         --
│    └─MaxPool2d: 2-3                    --
├─Sequential: 1-2                        --
│    └─Conv2d: 2-4                       73,856
│    └─ReLU: 2-5                         --
│    └─MaxPool2d: 2-6                    --
├─Sequential: 1-3                        --
│    └─Conv2d: 2-7                       295,168
│    └─ReLU: 2-8                         --
│    └─MaxPool2d: 2-9                    --
├─Sequential: 1-4                        --
│    └─Conv2d: 2-10                      1,180,160
│    └─ReLU: 2-11                        --
│    └─MaxPool2d: 2-12                   --
├─Sequential: 1-5                        --
│    └─Flatten: 2-13                     --
│    └─Linear: 2-14                      62,918,656
│    └─Dropout: 2-15                     --
│    └─ReLU: 2-16                        --
│    └─Linear: 2-17                      589,968
=================================================================
Total params: 65,058,448
Trainable params: 65,058,448
Non-trainable params: 0
=================================================================			
			]]>
			</screen>
		</section>
	</section>
	<section>
		<title>显卡</title>
		<programlisting>
			<![CDATA[
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)			
			]]>
		</programlisting>
	</section>
	<section id="pytorch.tensor">
		<title>Tensor 张量</title>
		<literallayout>
		<![CDATA[
Scalar(标量)：指一个数值
Vector(向量)：指一维数组
Matrix(矩阵)：指二维数组
Tensor(张量)：指大于二维的数组，即多位数组
		]]>
		</literallayout>
		<section>
			<title>创建静态 Tensor</title>
			<programlisting>
			<![CDATA[
import torch

tensor = torch.tensor([5, 8, 3, 7, 2, 4, 1, 0, 6, 9])
print(tensor)			
			]]>
			</programlisting>
		</section>
		<section>
			<title>创建连续数列的 Tensor</title>
			<programlisting>
			<![CDATA[
import torch

tensor = torch.range(1, 10)

print(tensor)			
			]]>
			</programlisting>
		</section>
		<section>
			<title>创建0数据的 Tensor</title>
			<para>创建一个 3x3 的 Tensor</para>
			<programlisting>
			<![CDATA[
import torch

x = torch.zeros(3, 3)
print(x)			
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
			]]>
			</screen>
		</section>
		<section>
			<title>判断变量是否为 Tensor</title>
			<programlisting>
			<![CDATA[
import torch

x = [1, 2, 3, 4, 5]
print(torch.is_tensor(x))

x1 = torch.rand(1, 2)
print(torch.is_tensor(x1))			
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
False
True			
			]]>
			</screen>

		</section>
		<section>
			<title>统计 Tensor 中的元素数量</title>
			<programlisting>
			<![CDATA[
import torch

x = torch.zeros(3, 3)
print(x)
print(torch.numel(x))	
			]]>
			</programlisting>
		</section>
		<section>
			<title>创建对角线为1的 Tensor</title>
			<programlisting>
			<![CDATA[
import torch

x = torch.eye(3, 3)
print(x)
print(torch.numel(x))			
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]])
9			
			]]>
			</screen>
		</section>
		<section>
			<title>将 numpy 转换成 tensor</title>
			<programlisting>
			<![CDATA[
import numpy
import torch

array = numpy.array([1, 2, 3, 4, 5])
print(array)
tensor = torch.from_numpy(array);
print(tensor)			
			]]>
			</programlisting>
			<para>输出结果</para>
			<programlisting>
			<![CDATA[
[1 2 3 4 5]
tensor([1, 2, 3, 4, 5])
			]]>
			</programlisting>
		</section>
		<section>
			<title>切分</title>
			<programlisting>
			<![CDATA[
tensor = torch.linspace(1, 9, 9)
print(tensor)
			]]>
			</programlisting>
			<screen>
			<![CDATA[
tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])			
			]]>
			</screen>
		</section>
		<section>
			<title>均匀分布数列</title>
			<para>返回值在0～1之间</para>
			<programlisting>
			<![CDATA[
tensor = torch.rand(10)
print(tensor)	
			]]>
			</programlisting>
			<screen>
			<![CDATA[
tensor([0.8865, 0.3672, 0.7740, 0.6729, 0.8264, 0.0811, 0.4243, 0.7992, 0.6984,
        0.1110])
			]]>
			</screen>
		</section>
		<section>
			<title>正态分布数列</title>
			<para>返回均值0，方差为1</para>
			<programlisting>
			<![CDATA[
tensor = torch.randn(10)
print(tensor)			
			]]>
			</programlisting>
			<para></para>
			<screen>
			<![CDATA[
tensor([-0.3631,  0.9288,  0.5677,  0.5674,  0.2578, -0.4731, -0.3581, -0.6288,
        -1.1815, -0.1885])			
			]]>
			</screen>
		</section>
		<section>
			<title>随机数列</title>
			<programlisting>
			<![CDATA[
import torch

tensor = torch.randperm(10)
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([5, 8, 3, 6, 0, 7, 1, 4, 2, 9])
			]]>
			</screen>
			<programlisting>
			<![CDATA[
import torch

tensor = torch.randint(1, 10, (3, 3))
print(tensor)			
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([[6, 1, 9],
        [4, 3, 6],
        [4, 8, 4]])
			]]>
			</screen>
		</section>
		<section id="torch.arange">
			<title>arange 创建等差数列</title>
			<para>arange(start=0, end, step=1, *, out=None, dtype=None,
				layout=torch.strided, device=None, requires_grad=False) -> Tensor
			</para>
			<para>参数</para>
			<literallayout>
		<![CDATA[
start (数字) – 起始值。默认值：0。
end (数字) – 结束值
step (数字) – 每对相邻数字之间的步长。默认值：1。
		]]>
			</literallayout>
			<para>关键字参数</para>
			<literallayout>
		<![CDATA[
out (张量, 可选) – 输出张量。
dtype (torch.dtype，可选) – 据类型。默认值：如果为 None，则使用全局默认值（请参阅 torch.set_default_dtype()）。如果未提供 dtype，则从其他输入参数推断数据类型。如果 start、end 或 stop 中的任何一个是浮点数，则 dtype 推断为默认 dtype，请参阅 get_default_dtype()。否则，dtype 推断为 torch.int64。
layout (torch.layout，可选) – 布局。默认值：torch.strided。
device (torch.device，可选) – 目标设备。默认值：如果为None，则使用默认张量类型当前的设备（参见 torch.set_default_device()）。对于 CPU 张量类型，device 将为 CPU；对于 CUDA 张量类型，device 将为当前的 CUDA 设备。
requires_grad (bool, 可选) – autograd 是否应记录返回张量上的操作。默认值：False。				
		]]>
			</literallayout>
			<programlisting>
		<![CDATA[
>>> torch.arange(5)  # 默认以 0 为起点
tensor([ 0,  1,  2,  3,  4])
>>> torch.arange(1, 4)  # 默认间隔为 1
tensor([ 1,  2,  3])
>>> torch.arange(1, 2.5, 0.5)  # 指定间隔 0.5
tensor([ 1.0000,  1.5000,  2.0000])		
		]]>
			</programlisting>
			<para></para>
			<programlisting>
		<![CDATA[
import torch
from torch.utils.data import Dataset, DataLoader
#
data = torch.arange(15)
print(data)		
		]]>
			</programlisting>
			<screen>
		<![CDATA[
tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])		
		]]>
			</screen>
			<programlisting>
			<![CDATA[
import torch

tensor = torch.arange(1, 10, 1)
print(tensor)
tensor = torch.arange(1, 10, 2)
print(tensor)
tensor = torch.arange(1, 10, 3)
print(tensor)
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])
tensor([1, 3, 5, 7, 9])
tensor([1, 4, 7])			
			]]>
			</screen>
			<programlisting>
		<![CDATA[
data = torch.arange(15).reshape(5,3)
print(data)		
		]]>
			</programlisting>
			<screen>
		<![CDATA[
tensor([[ 0,  1,  2],
        [ 3,  4,  5],
        [ 6,  7,  8],
        [ 9, 10, 11],
        [12, 13, 14]])		
		]]>
			</screen>
		</section>

		<section>
			<title>获取最小值和最大值的索引</title>
			<programlisting>
			<![CDATA[
import torch

tensor = torch.randint(1, 10, (3, 3))
print(tensor)
min = torch.argmin(tensor, dim=0)
print(min)
max = torch.argmax(tensor, dim=0)
print(max)			
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([[5, 1, 4],
        [7, 7, 8],
        [2, 2, 9]])
tensor([2, 0, 0])
tensor([1, 1, 2])			
			]]>
			</screen>
			<para>最小值返回索引 tensor([2, 0, 0])，2
				表示列第三个，0表示第二列第一个，最后一个0表示第三列第一个，最终可以获得 2，1，4 三个数据
			</para>
			<para>最大值返回索引 tensor([1, 1, 2])，对应数据 7，7，9</para>
		</section>
		<section>
			<title>连接两个 Tensor</title>
			<para>垂直连续，追加数据</para>
			<programlisting>
			<![CDATA[
import torch

tensor1 = torch.randint(1, 10, (3, 3))
print(tensor1)

tensor2 = torch.randint(1, 10, (3, 3))
print(tensor2)

tensor = torch.cat((tensor1, tensor2))
print(tensor)			
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([[1, 7, 5],
        [8, 6, 8],
        [6, 9, 2]])
tensor([[6, 5, 6],
        [4, 2, 2],
        [5, 9, 3]])
tensor([[1, 7, 5],
        [8, 6, 8],
        [6, 9, 2],
        [6, 5, 6],
        [4, 2, 2],
        [5, 9, 3]])			
			]]>
			</screen>
			<para>水平连接，扩展数据</para>
			<programlisting>
			<![CDATA[
import torch

tensor1 = torch.randint(1, 10, (3, 3))
print(tensor1)

tensor2 = torch.randint(1, 10, (3, 3))
print(tensor2)

tensor = torch.cat((tensor1, tensor2), dim=1)
print(tensor)			
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([[6, 1, 6],
        [9, 4, 9],
        [5, 7, 5]])
tensor([[5, 9, 9],
        [2, 3, 8],
        [5, 2, 8]])
tensor([[6, 1, 6, 5, 9, 9],
        [9, 4, 9, 2, 3, 8],
        [5, 7, 5, 5, 2, 8]])
			]]>
			</screen>
		</section>
		<section>
			<title>数据切块</title>
			<programlisting>
			<![CDATA[
import torch

tensor = torch.randint(1, 10, (3, 3))
print(tensor)

# 将 tensor 切成 3 份
tensor1 = torch.chunk(tensor, 3)
print(tensor1)

# 基于 Y 轴将 tensor 切成 3 份
tensor2 = torch.chunk(tensor, 3, dim=1)
print(tensor2)			
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([[7, 5, 6],
        [3, 5, 5],
        [2, 1, 8]])
(tensor([[7, 5, 6]]), tensor([[3, 5, 5]]), tensor([[2, 1, 8]]))
(tensor([[7],
        [3],
        [2]]), tensor([[5],
        [5],
        [1]]), tensor([[6],
        [5],
        [8]]))			
			]]>
			</screen>
		</section>
		<section>
			<title>通过索引下标选择数据</title>
			<programlisting>
			<![CDATA[
import torch

x = torch.randn(6, 6)
print(x)
index = torch.tensor([1, 3, 5])

tensor = torch.index_select(input=x, dim=0, index=index)
print(tensor)			
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([[ 0.2502,  0.0171,  0.0468, -1.1985,  0.1249, -0.2472],
        [-1.0763, -0.9561,  0.7500,  0.0903, -0.2404,  0.7940],
        [-0.2090, -1.1881,  0.6415, -1.8224, -1.2121,  0.0428],
        [-1.3796, -0.3021, -0.0945,  0.1808, -0.1802, -1.6069],
        [-1.0586,  0.0227, -0.4314, -0.4522, -0.6734,  0.0220],
        [-0.3171, -0.9069,  1.9850,  0.9845, -0.5600, -1.3951]])
tensor([[-1.0763, -0.9561,  0.7500,  0.0903, -0.2404,  0.7940],
        [-1.3796, -0.3021, -0.0945,  0.1808, -0.1802, -1.6069],
        [-0.3171, -0.9069,  1.9850,  0.9845, -0.5600, -1.3951]])			
			]]>
			</screen>
		</section>
		<section>
			<title>分割</title>
			<programlisting>
			<![CDATA[
import torch

tensor = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
print(tensor)
print(torch.split(tensor, 3))			
			]]>
			</programlisting>
			<screen>
			<![CDATA[
tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])
(tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9]), tensor([10]))			
			]]>
			</screen>
		</section>
		<section>
			<title>矩阵转换</title>
			<para>行列转换</para>
			<programlisting>
			<![CDATA[
import torch

tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(tensor)
print(tensor.t())
print(tensor.transpose(1, 0))
			]]>
			</programlisting>
			<para>输出结果</para>
			<screen>
			<![CDATA[
tensor([[1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]])
tensor([[1, 4, 7],
        [2, 5, 8],
        [3, 6, 9]])	
tensor([[1, 4, 7],
        [2, 5, 8],
        [3, 6, 9]])	        
			]]>
			</screen>
		</section>
		<section>
			<title>矩阵运算</title>
			<programlisting>
			<![CDATA[
import torch

tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(tensor)
print(torch.add(tensor, 1))
print(torch.mul(tensor, 2))			
			]]>
			</programlisting>
			<programlisting>
			<![CDATA[
import torch 
a=torch.tensor([[1,2,3],[4,5,6]])
b=torch.tensor([[2,3,4],[5,6,7]])
c=torch.mul(a,b)
print('a:',a)
print('b:',b)
print('c:',c)			
			]]>
			</programlisting>
		</section>
	</section>


	<section>
		<title>Dataset</title>
		<programlisting>
			<![CDATA[
import torch
from torch.utils.data import Dataset, DataLoader

x = torch.arange(15).reshape(5, 3)
# print(x)
y = torch.arange(5).reshape(5, 1)


# print(y)
class MyDataset(Dataset):
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def __len__(self):
        return len(self.x)

    def __getitem__(self, item):
        x = self.x[item]
        y = self.y[item]
        return x, y


dataset = MyDataset(x, y)
print(len(dataset))
print(dataset.x)
print(dataset.y)
print(dataset[1])

loader = DataLoader(dataset, batch_size=2, shuffle=True)
for i, data in enumerate(loader):
    print(i, data)			
			]]>
		</programlisting>
		<para>输出结果</para>
		<screen>
		<![CDATA[
5
tensor([[ 0,  1,  2],
        [ 3,  4,  5],
        [ 6,  7,  8],
        [ 9, 10, 11],
        [12, 13, 14]])
tensor([[0],
        [1],
        [2],
        [3],
        [4]])
(tensor([3, 4, 5]), tensor([1]))
0 [tensor([[ 3,  4,  5],
        [12, 13, 14]]), tensor([[1],
        [4]])]
1 [tensor([[6, 7, 8],
        [0, 1, 2]]), tensor([[2],
        [0]])]
2 [tensor([[ 9, 10, 11]]), tensor([[3]])]		
		]]>
		</screen>

	</section>
	<section>
		<title>DataLoader</title>
		<screen>
			<![CDATA[
batch_size = 32
train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True) 
#shuffle 将训练模型的数据集打乱。
test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size)
			]]>
		</screen>
		<section>
			<title>显示数据集中的图片</title>
			<programlisting>
		<![CDATA[
from torchvision import datasets
from torch.utils.data import DataLoader
from matplotlib import pyplot as plt

if __name__ == '__main__':
    train_datasets = datasets.CIFAR10(root='data', train=False, download=True)
    train_dataloader = DataLoader(train_datasets, batch_size=10, shuffle=False)

    fig, axes = plt.subplots(3, 3, figsize=(4, 4))

    for i, ax in enumerate(axes.flat):
        ax.imshow(train_dataloader.dataset.data[i])
        ax.axis("off")
        ax.set_title(train_dataloader.dataset.classes[train_dataloader.dataset.targets[i]])
    plt.show()
		
		]]>
			</programlisting>
		</section>
	</section>

	<section>
		<title>Module</title>
		<programlisting>
			<![CDATA[
import torch
from torch import nn

class MyModel(nn.Module):
    def __init__(self)->None:
        super().__init__()

        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=5,stride=1,padding=2)
        self.maxpool1 = nn.MaxPool2d(kernel_size=2)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=2, padding=2)
        self.maxpool2 = nn.MaxPool2d(kernel_size=2)
        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)
        self.maxpool3 = nn.MaxPool2d(kernel_size=2)

        self.flatten = nn.Flatten()
        self.linear1 = nn.Linear(1024,64)
        self.linear2 = nn.Linear(64, 10)
        self.softmax = nn.Softmax(dim=1)

    def forward(self,x):
        x = self.conv1(x)
        x = self.maxpool1(x)

        x = self.conv2(x)
        x = self.maxpool2(x)

        x = self.conv3(x)
        x = self.maxpool3(x)

        return x

inputs = torch.randn(1,3,32,32)
myModel = MyModel()
outputs = myModel(inputs)
print(outputs)
			]]>
		</programlisting>
	</section>
	&section.ai.torchvision.xml;
	<section id="tensorboard">
		<title>tensorboard</title>
		<programlisting>
		<![CDATA[
import os

from PIL import Image
from torch.utils.data import Dataset
from torchvision  import transforms
from torch.utils.tensorboard import SummaryWriter

import common
class mydatasets(Dataset):
    def __init__(self,root_dir):
       super(mydatasets, self).__init__()
       self.images=[ os.path.join(root_dir,image_name) for image_name in os.listdir(root_dir)]

       self.transforms=transforms.Compose([
           transforms.Resize((60,160)),
           transforms.ToTensor(),
           transforms.Grayscale()

       ])
    def __getitem__(self, index):
        image_path = self.images[index]
        image = Image.open(image_path)
        image_name=image_path.split("/")[-1]
        data=self.transforms(image)
        img_lable=image_name.split("_")[0]
        img_lable=common.text2vec(img_lable)
        lable=img_lable.view(1,-1)[0]
        return data,lable
    def __len__(self):
        return self.images.__len__()



if __name__ == '__main__':

    # d=mydatasets("./data/train")
    d = mydatasets("./data/test")
    img,label=d[0]
    writer=SummaryWriter("logs")
    writer.add_image("img",img,1)
    print(img.shape)
    writer.close()
		
		]]>
		</programlisting>
	</section>
</chapter>