<?xml version="1.0" encoding="UTF-8"?>
<section id="yolo">
	<title>YOLO</title>
	<orderedlist>
		<title>目标检测任务</title>
		<listitem>YOLO11：用于经典的目标检测任务。</listitem>
		<listitem>YOLO11-seg：用于实例分割，识别和分割图像中的对象。</listitem>
		<listitem>YOLO11-pose：用于关键点姿态估计，即确定人体的关键点（如关节位置）。</listitem>
		<listitem>YOLO11-obb：用于定向检测，可以识别并确定具有方向性物体的边界框（例如倾斜的目标物体）。</listitem>
		<listitem>YOLO11-cls：用于分类，负责对图像中的对象进行类别识别。</listitem>
	</orderedlist>
	<orderedlist>
		<title>模型规格</title>
		<listitem>YOLOv8 Nano	非常小	YOLOv8n</listitem>
		<listitem>YOLOv8 Small	小	YOLOv8s</listitem>
		<listitem>YOLOv8 Medium	中	YOLOv8m</listitem>
		<listitem>YOLOv8 Large	大	YOLOv8l</listitem>
		<listitem>YOLOv8 X（Extra Large）	非常大	YOLOv8x</listitem>
	</orderedlist>
	<section>
		<title>labels 文件格式</title>
		<para>x,y是目标的中心坐标，width,height是目标的宽和高。</para>
		<screen>
		<![CDATA[
<object-class> <x> <y> <width> <height>		
		]]>
		</screen>
		<para>VOC与YOLO之间的格式转换</para>
		<programlisting>
		<![CDATA[
# size是原图的（w,h), box是坐标

def voc_to_yolo(size, box):
    dw = 1./size[0]
    dh = 1./size[1]
    x = (box[0] + box[1])/2.0
    y = (box[2] + box[3])/2.0
    w = box[1] - box[0]
    h = box[3] - box[2]
    x = x*dw
    w = w*dw
    y = y*dh
    h = h*dh
    return (x,y,w,h)
 
def yolo_to_voc(size, box):
    x = box[0] * size[0]
    w = box[2] * size[0]
    y = box[1] * size[1]
    h = box[3] * size[1]
    xmin = int(x - w/2)
    xmax = int(x + w/2)
    ymin = int(y - h/2)
    ymax = int(y + h/2)
    return (xmin, ymin, xmax, ymax)
		
		]]>
		</programlisting>
	</section>
	
	<section>
		<title>模型训练</title>
		<programlisting>
		<![CDATA[
from ultralytics import YOLO
# 指定模型
mode = YOLO('yolo11n-seg.pt')
# 让模型开始训练
mode.train(data='dataset.yaml',workers=0,epochs=10,batch=10)
# 验证模型
mode.val()		
		]]>
		</programlisting>
	</section>
	<section>
		<title>模型评估</title>
		<programlisting>
		<![CDATA[
from ultralytics import YOLO
# ---------- 加载模型 ----------
model = YOLO('runs/detect/train/weights/best.pt')
# ---------- 模型评估 ----------
model.val(data='captcha/images/YOLODataset/dataset.yaml')
		
		]]>
		</programlisting>
	</section>
	<section>
		<title>模型预测</title>
		<programlisting>
		<![CDATA[
from ultralytics import YOLO

# 加载预训练的YOLOv11n模型
model = YOLO("yolo11n.pt")  # yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11x.pt

# 对'bus.jpg'图像进行推理，并获取结果 https://ultralytics.com/images/bus.jpg
results = model.predict("https://ultralytics.com/images/bus.jpg", save=True, imgsz=320, conf=0.5)

# 处理返回的结果
for result in results:
    boxes = result.boxes  # 获取边界框信息
    probs = result.probs  # 获取分类概率
    result.show()  # 显示结果型的架构
    print(boxes)
    print(probs)		
		]]>
		</programlisting>
		<para>换一个模型，试试 yolo11n-seg.pt</para>
		<programlisting>
		<![CDATA[
from ultralytics import YOLO

model = YOLO("yolo11n-seg.pt")
results = model.predict("https://ultralytics.com/images/bus.jpg", save=True, imgsz=320, conf=0.5)

# 处理返回的结果
for result in results:
    boxes = result.boxes  # 获取边界框信息
    probs = result.probs  # 获取分类概率
    print(boxes)
    print(probs)
    result.show()  # 显示结果型的架构		
		]]>
		</programlisting>
		
		<section>
			<title>predict 参数</title>
			<programlisting>
			<![CDATA[
from yolov8 import YOLO
 
# 加载预训练模型
model = YOLO('yolov8.pt')
 
# 执行预测
results = model.predict(
    source='path/to/image.jpg',  # 输入源，可以是图像路径、视频路径、摄像头索引等
    conf=0.5,                    # 置信度阈值，滤除低于该置信度的检测结果。
    iou=0.45,                    # NMS的交并比阈值，用于消除重叠的检测框。
    device='cuda',               # 使用GPU
    imgsz=(640, 640),            # 输入图像的尺寸，可以是单个整数（长宽相等）或元组（长和宽）。
    half=False,                  # 不使用半精度浮点数
    save_txt=True,               # 保存预测结果为文本文件
    save_conf=True,              # 在保存的文本文件中包含置信度
    save_crop=False,             # 不保存裁剪后的检测结果
    save_img=True,               # 保存带有检测框的图像
    classes=[0, 1, 2],           # 仅检测指定的类
    agnostic_nms=False,          # 不使用类别无关的NMS
    augment=False,               # 不使用数据增强
    visualize=False,             # 不可视化特征图
    project='runs/detect',       # 保存预测结果的项目目录
    name='exp',                  # 保存预测结果的子目录名称
    exist_ok=False,              # 不允许项目目录存在
    line_thickness=3,            # 绘制检测框的线条粗细
    hide_labels=False,           # 显示检测框的标签
    hide_conf=False              # 显示检测框的置信度
)
 
# 输出预测结果
print(results)
			
			]]>
			</programlisting>
		</section>
		<section>
			<title>返回结果</title>
			<para>返回结果通常包含以下主要属性和方法：</para>
			<literallayout>
			<![CDATA[
1.boxes: 包含检测到的边界框信息的对象。
2.scores: 包含每个检测目标的置信度分数。
3.classes: 包含每个检测目标的类别索引。
4.masks: 如果使用实例分割模型，包含分割掩码。
5.keypoints: 如果使用关键点检测模型，包含关键点信息。
6.orig_img: 原始输入图像。
7.plot(): 用于可视化检测结果的方法。			
			]]>
			</literallayout>
			<para>boxes: </para>
			<literallayout>
			<![CDATA[
1.boxes.xyxy: 返回每个检测目标的边界框坐标，格式为 [x_min, y_min, x_max, y_max]。
2.boxes.conf: 返回每个检测目标的置信度分数。
3.boxes.cls: 返回每个检测目标的类别索引。			
			]]>
			</literallayout>
		</section>
		<section>
			<title>提取标签</title>
			<programlisting>
			<![CDATA[
from ultralytics import YOLO

# 加载模型
# model = YOLO("yolo11n.pt")
# model = YOLO('weights/last.pt')
model = YOLO('weights/best.pt')

# 模型预测，save=True 的时候表示直接保存yolov8的预测结果
results = model('images/0_5902.png')

# View results
for result in results:
    # 处理结果
    boxes = result.boxes  # 边界框结果
    masks = result.masks  # 分割掩码结果
    names = result.names
    keypoints = result.keypoints  # 关键点检测结果
    probs = result.probs  # 分类概率结果
    obb = result.obb  # 方向边界框结果（OBB）
    print(boxes)
    for box in boxes:
        print(names[int(box.cls)])
    result.show()  # 显示结果			
			]]>
			</programlisting>
		</section>
		<section>
			<title>保存识别图像</title>
			<programlisting>
			<![CDATA[
@app.post("/netkiller")
async def netkiller(file: bytes = File()):
    try:
        filename = f"tmp/{uuid.uuid4()}.png"
        print(filename)
        with open(filename, "wb") as f:
            f.write(file)

        results = model(filename) # , conf=0.45

        for result in results:
            boxes = result.boxes  # 获取边界框信息
            # probs = result.probs  # 获取分类概率
            names = result.names
            data = result.boxes.data
            print(boxes)
            # print(probs)
            if names is not None:
                labels = []
                for box in boxes:
                    label = names[int(box.cls)]
                    labels.append(label)
                    print(label)
                # result.show()  # 显示结果型的架构
                result.save(filename="tmp/test.png")

            if boxes is not None:
                image = Image.open(filename)
                # x0, y0, x1, y1 = map(int, boxes.xyxy[0])
                crop = tuple(map(int, boxes.xyxy[0]))

                region = image.crop(crop)
                region.save('tmp/neo.jpg')

            return {"label": labels}
    except Exception as e:
        log.error(e)
    return {"label": None}			
			]]>
			</programlisting>
		</section>
	</section>
	<section>
		<title>模型导出</title>
		<section>
			<title>onnx 格式</title>
			<screen>
			<![CDATA[
(.venv) neo@Neo-Mac-mini netkiller % pip install onnx onnxslim -i https://pypi.tuna.tsinghua.edu.cn/simple		
			]]>
			</screen>
			<programlisting>
			<![CDATA[
from ultralytics import YOLO

model = YOLO("yolo11n.pt")
model.export(format="onnx")

# 预测看下效果
onnx_model = YOLO("yolo11n.onnx", task="detect")
results = onnx_model("https://ultralytics.com/images/bus.jpg")
results[0].show()		
			]]>
			</programlisting>
		</section>
		<section>
			<title>engine 格式</title>
			<programlisting>
			<![CDATA[
from ultralytics import YOLO

model = YOLO("yolo11n.pt")
model.export(format="engine")
tensorrt_model = YOLO("yolo11n.engine", task="detect")
results = tensorrt_model("https://ultralytics.com/images/bus.jpg")
results[0].show()			
			]]>
			</programlisting>
		</section>

	</section>
</section>